Speaker 1: Okay, let's unpack this. It's like trying to drink from a fire hose of information, isn't it?
Speaker 2: Absolutely.
Speaker 1: Facts, opinions, um, articles, social feeds, AI answers. It's just constantly coming at us.
Speaker 2: Yeah.
Speaker 1: So, how do we keep from drowning in it all, let alone figure out what's actually, you know, true?
Speaker 2: That's the million-dollar question right now.
Speaker 1: Our mission today really is to offer you a shortcut, a way to get well informed, equipped with those critical thinking skills.
Speaker 2: We're doing a deep dive into evaluating sources. We'll look at why this is so vital now, maybe more than ever.
Speaker 1: Definitely more than ever.
Speaker 2: We'll pull back the curtain on how things like AI, search engines, even academic databases actually work behind the scenes,
Speaker 1: right? The mechanics of it,
Speaker 2: and crucially help you spot the many forms of bias, the obvious ones, the subtle ones, and yeah, even the biases we carry ourselves.
Speaker 1: Yeah. And what's fascinating here is that the sheer volume of information doesn't automatically translate to better understanding. Not at all. In fact, it often demands a higher level of scrutiny from all of us. It's not about consuming more. It's about consuming smarter, uh, more strategically.
Speaker 2: Exactly. The internet just fundamentally changed the game, didn't it?
Speaker 1: Completely.
Speaker 2: It's no longer that information gets checked before it's shared.
Speaker 1: Now, well, anyone can publish anything instantly globally.
Speaker 2: Yeah. The floodgates are open.
Speaker 1: So, for some are just trying to grasp the facts. What's the immediate tangible value in getting better at evaluating sources? Why bother?
Speaker 2: Well, The immediate value is really clarity and certainty and your own understanding.
Speaker 1: Okay?
Speaker 2: Evaluating sources is basically your best defense against misinformation, propaganda, even just, you know, honest mistakes.
Speaker 1: It's how you make sure the conclusions you draw are sound, that the data actually supports the claims being made, and that you're hearing from, you know, genuinely knowledgeable experts, not just sources with an agenda or something to sell. It's about building a robust foundation of trust for your own knowledge. brings up such a critical point because well, we've always questioned human sources, right? But this rapid rise of AI, it adds a whole new layer of complexity. It
Speaker 2: really does.
Speaker 1: I've even heard some argue that AI could reduce bias, you know, by just processing pure data. Do you buy that or is that just wishful thinking?
Speaker 2: Uh, I'd say it's largely wishful thinking and actually quite dangerous thinking.
Speaker 1: Okay.
Speaker 2: Because AI just by its very nature has no inherent checks or oversight built in. It's designed to compile patterns from massive amounts of data which unfortunately includes potentially unreputable sources, flawed data, human biases baked right into the original content it learned from.
Speaker 1: So, it's learning our biases.
Speaker 2: It's reflecting and sometimes amplifying them. It doesn't learn like a human. It synthesizes patterns and the real world consequences can be pretty stark.
Speaker 1: Like what?
Speaker 2: Well, remember those lawyers? The ones sanctioned for citing eight completely non-existent AI generated fake court cases in their legal motions.
Speaker 1: Oh wow. Yeah, I heard about that. Eight fake cases.
Speaker 2: Exactly. That just powerfully illustrates the danger of unchecked AI output, especially in really high stakes situations.
Speaker 1: That's chilling. It really shows how quickly things escalate when we let our guard down with these systems. So, okay, we basically got these three main ways of finding information now. AI directly, traditional search engines, and then academic databases.
Speaker 2: Broadly,
Speaker 1: each has its own promise, its own pitfalls.
Speaker 2: Yeah.
Speaker 1: Let's start by peeling back the curtain on AI a bit more. What's really going on there?
Speaker 2: Okay, AI, the foundational truth, and it's simple but crucial, is garbage in, garbage out. It's only as good as the source as it was trained on. And it's fed these enormous data sets scraped from the internet, a real mix of accurate stuff, inaccurate stuff, even uncredited content like, you know, social media images or random blog posts.
Speaker 1: Just hoovering it all up
Speaker 2: pretty much. It's a phenomenal pattern matcher, incredibly sophisticated at that. But that distinction is vital. the creative hallucinations. It can sound plausible but be totally wrong.
Speaker 1: And you might think, well, a computer's neutral, right? It's just logic. But our sources show that's a really dangerous illusion, isn't it?
Speaker 2: Absolutely. That veneer of objectivity that comes with technology can actually make people less likely to question biased outputs
Speaker 1: because it feels objective.
Speaker 2: Exactly. But AI systems can absolutely perpetuate and amplify existing societal biases. Take the Gender Shades project that was groundbreaking.
Speaker 1: What did it find?
Speaker 2: It revealed how AI facial recognition systems because they were trained on biased data performed significantly worse at identifying gender in darkerkinned females compared to lighterkinned males. Huge difference.
Speaker 1: Or more recently, a 2023 analysis found that generative AI tools like stable diffusion, the image generators, explicitly amplify gender and racial stereotypes in the images they create.
Speaker 2: So these biases aren't just abstract ideas, they have real world impacts.
Speaker 1: Profound real world impacts definitely.
Speaker 2: Okay, so if AI is already, you know, a bit of a minefield, what about search engines, our daily digital compass? What are the unseen forces directing our clicks and shaping our view of the world there?
Speaker 1: Search engines, right? They use these incredibly complex algorithms to decide which links to show you for your query.
Speaker 2: The magic formula
Speaker 1: kind of. And These algorithms prioritize what they deem most important or relevant to you. But here's the key. That determination isn't primarily about factual accuracy.
Speaker 2: It's not. What is it based on then?
Speaker 1: It's based on factors like keywords, your past search, your location, what other people click on, and search engine optimization or SEO. How well a page is designed to rank high.
Speaker 2: And let's be honest, most of us, we rarely look past the first page of results, right? Maybe not even the first few links.
Speaker 1: That's exactly right. Which means we're incredibly susceptible to whatever those algorithms decide to bubble up to the top.
Speaker 2: So, it's not just showing us what's out there. It's actively shaping our reality based on what it thinks we want to see. You mentioned calling it a bias machine.
Speaker 1: It truly can function as a bias machine as a BBC article aptly put it. Consider this example they found.
Speaker 2: Search is Kla Harris a good Democratic candidate and Google tends to surface positive results like Harris energizes Democrats.
Speaker 1: But then search is Kla Harris a bad Democrat? atic candidate and suddenly you get a stream of critical articles. It's tailoring the results to the implied sentiment of your query.
Speaker 2: Even pulling contradictory info from the same source sometimes.
Speaker 1: Yes, that's even more subtle. A search for say link between coffee and hypertension might pull a featured snippet saying caffeine increases blood pressure. But search no link between coffee and hypertension and it might pull a line from the exact same Mayo Clinic article saying caffeine doesn't have a long-term effect.
Speaker 2: How does that happen? Because as Google's own internal documents admitted years ago, we do not understand documents. We fake it. They rely heavily on user clicks and other signals to predict relevance. It's feeding you what it thinks you're looking for based on the phrasing, not necessarily the complete nuanced truth.
Speaker 1: Wow. And now search engines are even bringing AI directly into the mix with things like AI overviews.
Speaker 2: Exactly.
Speaker 1: Which just sounds like it compounds these issues, presenting those curated algorithm-driven responses as definitive answers.
Speaker 2: Precisely. It takes that answer engine idea to a new level. The system itself generates a response, often without clear attribution to its underlying sources, potentially embedding AI bias or hallucinations directly into what looks like a factual summary. Another layer of complexity.
Speaker 1: Okay, let's shift gears then. Let's talk about academic databases. For many people, these feel like a totally different universe from the wild west of the general internet, like a beacon of rigorous, vetted information.
Speaker 2: And they often are. Academic databases offer a primary really crucial advantage. They mostly contain articles and research that have gone through rigorous checking primarily peer review.
Speaker 1: Peer review meaning
Speaker 2: meaning other experts in the same field have scrutinized the research methods, the data, the conclusions before it gets published. So the content is generally vetted by the broader academic or scientific community.
Speaker 1: So a certain level of credibility is baked in.
Speaker 2: Generally, yes. Plus, they offer much better tools for narrowing your searches, filtering by date, subject, publication type, and they're organized by subject area, making it easier to find relevant, highquality information.
Speaker 1: The difference in the kind of information you get seems huge. You shared a great example comparing Google in a database,
Speaker 2: right? A search for impact of social media on teenagers in Google might give you, say, 81 million results, tons of ads, blogs, news articles, a real mix.
Speaker 1: Yeah, overwhelming.
Speaker 2: The same search in an academic database like Academic Search Premiere, it might return just 10 results, but they'd likely be peer- reviewviewed. articles from academic journals directly addressing the research question.
Speaker 1: That's a massive difference in focus and presumably trustworthiness right off the bat.
Speaker 2: It's a stark contrast. Yeah, it really highlights the value of these curated resources. You're often trading sheer quantity for quality and reliability.
Speaker 1: But you mentioned a caveat even here.
Speaker 2: Yes, a crucial one. You still have to be careful of what are sometimes called paytoplay or predatory journals. These are publications where acceptance might be prioritized over rigorous peer review. Basically because the authors pay a hefty fee.
Speaker 1: Ah so the financial incentive might compromise the vetting process.
Speaker 2: It potentially can. So it's always wise to doublech checkck the reputation of the journal itself even within an academic database.
Speaker 1: Good tip. Okay. So we've talked about the landscapes AI search academic databases. But weaving through all of this no matter where you get your info is this invisible force shaping it.
Speaker 2: Bias.
Speaker 1: Absolutely.
Speaker 2: And it's not just out there in the media. It's also you know within us too. Right.
Speaker 1: That's a really profound truth. When we talk about media bias, we mean the inherently subjective processes involved in selecting information, curating it, framing it, which can lead to skewed, incomplete, or misrepresented reporting.
Speaker 2: It's unavoidable to some extent.
Speaker 1: Well, it's important to understand that some level of bias is practically unavoidable. You simply can't report every single fact about an event or tell a story without some kind of narrative framing. Choices have to be made.
Speaker 2: And this is where it gets really personal, I think. We all have internal biases even if we don't think we do. We all see things through our own lenses
Speaker 1: and everyone producing information has an agenda. Some are obvious, some less so. But it affects how stuff is presented and just as importantly how we interpret it.
Speaker 2: Precisely. Our own internal biases, confirmation bias, affinity bias, you name it, unconsciously influence our perspective. It affects everything. Yeah.
Speaker 1: The specific words chosen like using passive voice in news reports about victims which can subtly shift blame
Speaker 2: right
Speaker 1: to how a story is framed overall and even what stories get chosen to be reported in the first place and when you get into controversial or hot topics the stakes feel higher and unfortunately the inclination to misrepresent facts or even lie can increase
Speaker 2: we don't have time to list every single type of bias obviously but maybe we can hit a few of the big hitters that people encounter daily like confirmation bias that feels like a huge one
Speaker 1: oh absolutely think of confirmation bias as your brain's natural echo chamber
Speaker 2: huh good way to put it.
Speaker 1: It's our tendency to seek out, interpret, and remember information that confirms beliefs we already hold while dismissing or downplaying anything that challenges them. You know, I catch myself doing it if I'm looking up say, "Are audio books as good as reading?" I might subconsciously click the article saying yes first. It's just human nature.
Speaker 2: It's embarrassingly relatable. Yeah.
Speaker 1: Another really pervasive one you mentioned is false balance or both sidesism.
Speaker 2: Ah, yes. This This is common in journalism. A Northwestern University study on climate change reporting really highlighted it.
Speaker 1: How so?
Speaker 2: It showed how journalists trying hard to appear balanced or objective would present what's actually an overwhelming scientific consensus on one side and just a few dissenting voices on the other as if it were a 50/50 debate.
Speaker 1: Right. Like 99 climate scientists versus one skeptic presented as equal sides.
Speaker 2: Exactly. Imagine 99 doctors telling you need life-saving surgery but one disagrees. You'd probably listen to the 99, right? But in media coverage, particularly on complex scientific or public health issues, climate change. Mask efficacy, presenting that tiny minority view as equally valid, damages public trust and makes critical issues seem less urgent or more debatable than the evidence suggests.
Speaker 1: Then there's the more obvious stuff like sensationalism and negativity bias. We see that everywhere online.
Speaker 2: Oh yeah, those millennials killed the napkin industry or RIP 70 things millennials have killed type headlines.
Speaker 1: Exactly. Clearly designed to provoke an emotional action and get clicks, not necessarily to inform accurately.
Speaker 2: And we absolutely can't forget corporate and partisan bias. It's often quite explicit. Fox News and MSNBC clearly lean right and left, respectively. You see media empires like Murdoch's consistently endorsing one political side across their outlets. Or corporate bias, where maybe a news outlet owned by a huge energy conglomerate might consistently downplay negative stories about fossil fuels or climate change because it affects the parent company. bottom line.
Speaker 1: And governments can influence coverage too, right?
Speaker 2: Definitely through strategic leaks to favored reporters or by selectively calling on certain journalists during press conferences. Market forces also play a huge role. Who owns the outlet? Who are the advertisers? Who is the intended audience? What gets clicks? It all shapes the final product.
Speaker 1: This all raises a really important question for everyone listening. How do you start to differentiate actual news reporting from opinion pieces?
Speaker 2: And maybe even harder, how Do you recognize your own preconceptions that might be coloring what you see or read?
Speaker 1: That's the core challenge. A key step is learning to differentiate between news reports, which should strive for objectivity and verification, and opinion columns or editorials, which are designed to express a specific viewpoint and persuade.
Speaker 2: Any quick tells?
Speaker 1: A quick mental check. Does it feel like it's primarily trying to tell you something strongly, evoke a specific emotion, use loaded language, or explicitly persuade you? It's likely opinion. News ideally shows you something. Presenting verified facts from multiple perspectives if possible. Also remember bias isn't usually a simple biased versus unbiased switch. It's a spectrum,
Speaker 2: right?
Speaker 1: And crucially recognizing our own biases is key. We all tend to misperceive or dismiss information that challenges our deeply held beliefs. There are tools out there actually like Harvard's Project Implicit. They have online tests that can help reveal unconscious associations. and biases you might not even know you have. It can be quite eye opening.
Speaker 2: So acknowledging that everyone including ourselves has a perspective or an agenda. That's really the first step towards thinking more critically.
Speaker 1: Exactly. It's foundational.
Speaker 2: Okay. This can definitely feel overwhelming when you consider all these factors. The platform, the source, the inherent biases, our own biases.
Speaker 1: It can seem like a lot,
Speaker 2: but we're not helpless. There are practical frameworks, tools we can use. You mentioned one earlier. Let's talk about the CRA ape test. Sounds funny, but it's useful. It does sound funny, but it's incredibly useful. C R A P. Think of it less like a rigid checklist you tick off and more like developing critical thinking muscle memory.
Speaker 1: Okay?
Speaker 2: It's a systematic framework for evaluating sources developed by librarian Sarah Blakesley. And the real insight isn't just knowing what the letters stand for, but understanding that all five elements really need to pass muster for a source to be considered truly reliable. One weak link like uh poor authority or a hidden purpose and and your understanding could be built on shaky ground,
Speaker 1: right? So, let's quickly run through them for our listeners. C is for
Speaker 2: currency. Is the information timely enough for your specific topic? When was it published or last updated?
Speaker 1: Okay, so timeliness. Is it recent? But also, is it too recent? Maybe missing historical context.
Speaker 2: Exactly. And are the links still working? Does it feel current for the field? For something like AI, 6 months is ancient history. For history, 60 years might be fine.
Speaker 1: Got it. R is four.
Speaker 2: Relevance. How important is this specific information? for your actual needs. Does it directly answer your question or is it just kind of related?
Speaker 1: Is the level right? Like not too basic, not too technical.
Speaker 2: Precisely. Have you looked at multiple sources to compare? And ultimately, would you feel comfortable citing this source in your own work or argument?
Speaker 1: Makes sense. Then we have two A's. The first A,
Speaker 2: authority. Who is the author, the publisher? The source, the sponsor. What are their credentials? Are they actually qualified to speak on this specific topic?
Speaker 1: Right. Like you said, A Nobel physicist isn't automatically an expert on marketing.
Speaker 2: Exactly. Is there contact information? What does the URL tell you? O.edu or.gov might suggest more authority than a.com, but not always. Andorg just means nonprofit, not necessarily unbiased or authoritative. You still have to check who the organization is.
Speaker 1: Okay. And the second A is for
Speaker 2: accuracy. This is a big one. How reliable, truthful, and correct is the content itself? Where does the information actually come from? Is it supported by evidence, citations, Can you verify it elsewhere? Like triangulate with other reliable sources.
Speaker 1: Yes, exactly. Has it been reviewed or refereed like peer review? Is the language and tone objective and impartial or is it loaded with emotion or errors? Spelling mistakes, grammar issues. Sometimes those are red flags, too.
Speaker 2: Good point. Okay. Finally, P is for
Speaker 1: purpose. Why does this information exist in the first place? What was the goal in creating it?
Speaker 2: Is it trying to inform, teach, sell something, entertain? persuade,
Speaker 1: right? Are the intentions of the author or publisher clear? Or is there maybe a hidden agenda? Is it presenting fact, opinion, or even propaganda? Are there obvious political, ideological, cultural, religious, institutional, or personal biases influencing it? Understanding the purpose helps you put everything else, the currency, the authority, the accuracy into the right context.
Speaker 2: So really, this isn't just about ticking bosses on a checklist. It's a way to actively, critically engage with everything you read, watch, or hear. Absolutely. It empowers you to make much more informed decisions about the information you decide to consume, trust, and maybe even share yourself.
Speaker 1: So, we've really unpacked a lot today from uh the wild west of online information to the hidden biases baked into even our most trusted sources and how AI is adding these entirely new layers of complexity to figuring out what's real.
Speaker 2: It's a complex landscape, no doubt. But the good news really is that just having an awareness of these dynamics, these different forces at playm And having practical tools like the CRA test in your mental toolkit means you are far far better equipped to navigate it all. You can start to discern what truly holds weight and what might be less reliable.
Speaker 1: It's about empowering yourself to be an active critical consumer, not just a passive recipient.
Speaker 2: Precisely.
Speaker 1: Which maybe leaves us with a final thought for everyone listening.
Speaker 2: In a world where algorithms are getting increasingly sophisticated and knowing exactly what you want to hear,
Speaker 1: how much more vital is it to actively make the effort to seek out what you actually need to know, even and maybe especially when it challenges your comfort zone.
Speaker 2: That's a powerful question to end on.
Speaker 1: That's the real deep dive.



